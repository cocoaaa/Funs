{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement $nCr$ in python\n",
    "As a variant of Depth First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nprint(*args, header=True):\n",
    "    if header:\n",
    "        print(\"=\"*80)\n",
    "    for arg in args:\n",
    "        print(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex and Edge classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vertex:\n",
    "    def __init__(self, vid):\n",
    "        self.vid = vid # integer\n",
    "        self.neighbors = set() # set of adjacent Vertex objects\n",
    "        \n",
    "    def add_neighbors(self, new_vs):\n",
    "        for new_v in new_vs:\n",
    "            self.neighbors.add(new_v)\n",
    "    def print_neighbors(self):\n",
    "        for v in self.neighbors:\n",
    "            print('\\t<->', v)\n",
    "            \n",
    "    def __eq__(self, other):\n",
    "        return self.vid == other.vid and self.neighbors == other.neighbors\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.vid > other.vid\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        return self == other or self > other\n",
    "    def __hash__(self):\n",
    "        return hash(self.vid)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Vertex {}\".format(self.vid) #\": connected to {}\".format(self.vid, [n.vid for n in self.neighbors])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UndirectedEdge:\n",
    "    def __init__(self, v1, v2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - v1, v2 (Vertex object)\n",
    "        \"\"\"\n",
    "        self.endpoints = set([v1,v2])\n",
    "        \n",
    "    def get_endpoints(self, toSort=True, **kwargs):\n",
    "        epts = list(self.endpoints)\n",
    "        if toSort:\n",
    "            epts.sort(**kwargs)\n",
    "        return epts\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash( tuple(self.get_endpoints(toSort=True)) )\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, UndirectedEdge):\n",
    "            return NotImplemented\n",
    "        return self.endpoints == other.endpoints\n",
    "    \n",
    "    def __str__(self):\n",
    "        v1, v2 = self.get_endpoints()\n",
    "        return \"Edge({} <-> {})\".format(v1.vid,v2.vid)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectedEdge:\n",
    "    def __init__(self, v1, v2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - v1, v2 (Vertex object)\n",
    "        \"\"\"\n",
    "        self.endpoints = (v1,v2)\n",
    "        \n",
    "    def get_endpoints(self):\n",
    "        return self.endpoints\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash( self.endpoints )\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, UndirectedEdge):\n",
    "            return NotImplemented\n",
    "        return self.endpoints == other.endpoints\n",
    "    \n",
    "    def __str__(self):\n",
    "        v1, v2 = self.endpoints\n",
    "        return \"Edge({} -> {})\".format(v1.vid,v2.vid)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undirected Graph Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UndirectedGraph:\n",
    "    def __init__(self, vertices):\n",
    "        self.V = {v.vid: v for v in vertices} # set of Vertex objs \n",
    "        \n",
    "        # create self.E based on the adjacency of Vertices in self.V\n",
    "        self.__init_edges_from_vertices()\n",
    "        \n",
    "    def __init_edges_from_vertices(self):\n",
    "        self.E = set()\n",
    "        for v in self.V.values():\n",
    "            for n in v.neighbors:\n",
    "                assert n.vid in self.V, \"Vertex {} not in Graph\".format(n.vid)\n",
    "                self.E.add(UndirectedEdge(v,n))\n",
    "\n",
    "    def __str__(self):\n",
    "        pass #todo: tree like printout\n",
    "    \n",
    "    def has_vertex(self, v):\n",
    "        return self.V[v.vid] == v\n",
    "    \n",
    "    def has_edge(self, e):\n",
    "        return e in self.E\n",
    "    \n",
    "    def add_vertex(self, v):\n",
    "        if v.vid in self.V:\n",
    "            print(\"No update: Vertex {} already in graph\".format(v.vid))\n",
    "        else: \n",
    "            self.V[v.vid] = v\n",
    "        \n",
    "    def add_edge(self, e):\n",
    "        v1, v2 = e.get_endpoints\n",
    "        if not (v1.vid in self.V and v2.vid in self.V):\n",
    "            raise ValueError(\"Both endpoints of the edge must in already in graph. Try add_vertex first\")\n",
    "        \n",
    "        # Add to graph\n",
    "        self.E.add(e)\n",
    "        \n",
    "        # Add to vertices' `neighbors`\n",
    "        v1.add_neighbors([v2])\n",
    "        v2.add_neighbors([v1])\n",
    "        \n",
    "        \n",
    "    def get_neighbors(self, vid):\n",
    "        return self.V[vid].neighbors\n",
    "    \n",
    "    def print_neighbors(self, vid):\n",
    "        return self.V[vid].print_neighbors()\n",
    "    \n",
    "    def print_edges(self):\n",
    "        for e in self.E:\n",
    "            print(e)\n",
    "    def print_structure(self):\n",
    "        for v in self.V.values():\n",
    "            print(\"=\"*80)\n",
    "            print(v)\n",
    "            v.print_neighbors()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed Graph Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectedGraph:\n",
    "    \"\"\"\n",
    "    Directed graph abstraction that contains a dictionary of Vertex objects\n",
    "    and a set of DirectedEdge objects\n",
    "    \n",
    "    Args:\n",
    "    - vertices (list): list of Vertex objects\n",
    "    \"\"\"\n",
    "    def __init__(self, vertices):\n",
    "        self.V = {v.vid: v for v in vertices} # set of Vertex objs \n",
    "        \n",
    "        # create self.E based on the adjacency of Vertices in self.V\n",
    "        self.__init_edges_from_vertices()\n",
    "        \n",
    "    def __init_edges_from_vertices(self):\n",
    "        self.E = set()\n",
    "        for v in self.V.values():\n",
    "            for n in v.neighbors:\n",
    "                assert n.vid in self.V, \"Vertex {} not in Graph\".format(n.vid)\n",
    "                self.E.add(DirectedEdge(v,n))\n",
    "\n",
    "    def __str__(self):\n",
    "        pass #todo: tree like printout\n",
    "    \n",
    "    def has_vertex(self, v):\n",
    "        return self.V[v.vid] == v\n",
    "    \n",
    "    def has_edge(self, e):\n",
    "        return e in self.E\n",
    "    \n",
    "    def add_vertex(self, v):\n",
    "        if v.vid in self.V:\n",
    "            print(\"No update: Vertex {} already in graph\".format(v.vid))\n",
    "        else: \n",
    "            self.V[v.vid] = v\n",
    "        \n",
    "    def add_edge(self, e):\n",
    "        \"\"\"Adds a directed edge\n",
    "        \"\"\"\n",
    "        if not isinstance(e, DirectedEdge):\n",
    "            raise TypeError(f\"{e} must be of type DirectedEdge: {type(e)}\")\n",
    "        v1, v2 = e.get_endpoints\n",
    "        if not (v1.vid in self.V and v2.vid in self.V):\n",
    "            raise ValueError(\"Both endpoints of the edge must in already in graph. Try add_vertex first\")\n",
    "        \n",
    "        # Add to graph\n",
    "        self.E.add(e)\n",
    "        \n",
    "        # Add to vertices' `neighbors`\n",
    "        v1.add_neighbors([v2])        \n",
    "        \n",
    "    def get_neighbors(self, vid):\n",
    "        return self.V[vid].neighbors\n",
    "    \n",
    "    def print_neighbors(self, vid):\n",
    "        return self.V[vid].print_neighbors()\n",
    "    \n",
    "    def print_edges(self):\n",
    "        for e in self.E:\n",
    "            print(e)\n",
    "    def print_structure(self):\n",
    "        for v in self.V.values():\n",
    "            print(\"=\"*80)\n",
    "            print(v)\n",
    "            v.print_neighbors()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAG Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAG(DirectedGraph):\n",
    "    \"\"\" \n",
    "    Fully connected DAG with vertices Vertex(0), Vertex(1), ..., Vertex(n-1)\n",
    "    \n",
    "    Args:\n",
    "    - n (int): number of vertices\n",
    "    \"\"\"\n",
    "    def __init__(self, n):\n",
    "        verts = [Vertex(i) for i in range(n)]\n",
    "        # add DAG edges\n",
    "        for i,v in enumerate(verts):\n",
    "            v.add_neighbors( [verts[j] for j in range(i+1, n)] )\n",
    "            \n",
    "        super().__init__(verts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Graph Path Class (ie. Node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Node representing a search path on a graph\n",
    "    \n",
    "    Args:\n",
    "    - vid (int): vertex id in a graph \n",
    "    - parent (Node): its parent Node object\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, vid, parent):\n",
    "        self.vid = vid\n",
    "        self.parent = parent \n",
    "        \n",
    "        # depth(ie. level) in the search tree\n",
    "        # Note a root is at level 1, not zero\n",
    "        self.path_len = 1 if parent is None else parent.path_len + 1 \n",
    "        self.depth = self.path_len #alias\n",
    "        \n",
    "    def __str__(self):\n",
    "        clsname =  self.__class__.__name__\n",
    "        return \"{}({}, p={}, depth={})\".format(clsname,\n",
    "                                             self.vid, \n",
    "                                            self.parent.vid if self.parent is not None else \"None\",\n",
    "                                            self.depth)\n",
    "# Alternate naming\n",
    "class Path(Node):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - vid (int): the id of the last vertex of this path\n",
    "    - parent (Path): Path object that represents the parent path (ie. path leading upto \n",
    "        the `end_vid`\n",
    "    - path_len (int): length of this path (ie. number of vertices on this path(\n",
    "    \"\"\"\n",
    "    def __init__(self, vid, parent):\n",
    "        super().__init__(vid, parent) #same as above\n",
    "        \n",
    "#     def __str__(self):\n",
    "#         NotImplemented\n",
    "#         pass #same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: 3/26(W) 9:10PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESUME HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombNode(Node):\n",
    "    \"\"\"\n",
    "    Combinatorial node\n",
    "    Each node instance contains self.vid = a set of elements(not the indices)\n",
    "    from the original list of elements\n",
    "    \n",
    "    Args:\n",
    "    - vid (frozenset): a set of elements from the orig_list\n",
    "        - Note this is not a set of indices (integers) indicating the element's index i\n",
    "    - parent( Node)\n",
    "    \n",
    "    Below two are problem-specific \n",
    "    - orig_list (list): the original list containing members (not its indices)\n",
    "    - binsizes (list or tuple): a list of binsizes to divide the elements in orig_list into.\n",
    "        It must satisfy that sum(binsize) == len(orig_list)\n",
    "    \n",
    "    For example, \n",
    "    - orig_list = [0,1,2,3,4] \n",
    "    - binsize could be (1,1,3) or (1,2,2) if we want to group the elements into three groups\n",
    "    or (1,4), (2,3) if into 2 groups.\n",
    "    \n",
    "    Another example,\n",
    "    - orig_list = ['highway' , 'primary', 'tertiary', 'residential', 'path', 'cycleway']\n",
    "    - binsize = (1,1,4), (1,2,3) if we want to group the elements into three groups\n",
    "    or (1,5), (2,4), (3,3) if into two groups\n",
    "    \"\"\"\n",
    "    def __init__(self, vid, parent, orig_list, binsizes):\n",
    "        if not isinstance(vid, set):\n",
    "            raise ValueError(\"vid must be a set: {}\".format(type(vid)))\n",
    "        if not isinstance(vid, frozenset):\n",
    "            vid = frozenset(vid)\n",
    "#         assert np.sum(binsizes) == len(orig_list), \"Binsize must sum upto {}\".format(len(orig_list))\n",
    "        \n",
    "\n",
    "        super().__init__(vid, parent)\n",
    "        \n",
    "        if not isinstance(orig_list, np.ndarray):\n",
    "            orig_list = np.array(orig_list)\n",
    "        self.orig_list = orig_list\n",
    "        self.binsizes = binsizes\n",
    "        \n",
    "        # element-based (not index-based) list history\n",
    "        _prev_remaining = self.parent.remaining if self.parent is not None else self.orig_list\n",
    "        self.remaining = np.array([ele for ele in _prev_remaining if ele not in self.vid])\n",
    "    \n",
    "    def get_children(self, verbose=False):\n",
    "        \"\"\"\n",
    "        Returns a list of its children nodes (CombNode objects)\n",
    "        \"\"\"\n",
    "        # If no more remaining elements, return right away\n",
    "        if len(self.remaining) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Find all possible combinations of size `k` from `self.remaining` list\n",
    "        n = len(self.remaining)\n",
    "        k = self.binsizes[self.depth] # children level's binsize since self.depth starts at 1\n",
    "        idxset_list = nCk(n, k)        \n",
    "        vidset_list = [ set(self.remaining[ list(idxset) ]) for idxset in idxset_list ]\n",
    "        \n",
    "        if verbose:\n",
    "            print('remaining elements: ', self.remaining)\n",
    "            print('child binsize: ', k)\n",
    "            print('idxset_list: ',idxset_list)\n",
    "            print('vidset_list: ',vidset_list)\n",
    "\n",
    "        \n",
    "        # Create CombNodes for children \n",
    "        children = [CombNode(vid=vidset, parent=self, orig_list=self.orig_list, binsizes=self.binsizes) \n",
    "                    for vidset in vidset_list]\n",
    "        return children\n",
    "    \n",
    "    def __str__(self):\n",
    "        clsname =  self.__class__.__name__\n",
    "        p = self.parent.vid if self.parent is not None else \"None\"\n",
    "        descr = ( f\"{clsname}({self.vid}, p={p}, level={self.path_len})\"\n",
    "#                   f\"\\n\\tOriginal: {self.orig_list}\"\n",
    "                  f\", Remaining: {self.remaining}\" )\n",
    "        return descr\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traceback function\n",
    "Print full path from Node $n$ till its root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace(n, tlist=None):\n",
    "    \"\"\"\n",
    "    Print full path from Node $n$ till its root\n",
    "    Args:\n",
    "    - n (Node):\n",
    "    - tlist (list or None): list of vertex ids (integers)\n",
    "    \"\"\"\n",
    "    if tlist is None: #n is the last node in the trace tree\n",
    "        tlist = []\n",
    "    tlist.append(n.vid)\n",
    "    \n",
    "    if n.parent is None: # n is the first node in the trace tree. End tracing.\n",
    "        return tlist\n",
    "    \n",
    "    # recurse\n",
    "    return get_trace(n.parent, tlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_trace():\n",
    "    v0 = Vertex(0); v1 = Vertex(1); v2 = Vertex(2); v3 = Vertex(3);\n",
    "\n",
    "    n0 = Node(v0, parent=None)\n",
    "    n1 = Node(v1, parent=n0)\n",
    "    n2 = Node(v2, parent=n0)\n",
    "\n",
    "    n3 = Node(v3, parent=n1)\n",
    "    print(\"n0: \", n0)\n",
    "    print(\"n1: \", n1)\n",
    "    print(\"n2: \", n2)\n",
    "#     print(\"trace of n0: \", get_trace(n0))\n",
    "#     print(\"trace of n1: \", get_trace(n1))\n",
    "#     print(\"trace of n2: \", get_trace(n2))\n",
    "    print(\"trace of n3: \", get_trace(n3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n0:  Node(Vertex 0, p=None, depth=1)\n",
      "n1:  Node(Vertex 1, p=Vertex 0, depth=2)\n",
      "n2:  Node(Vertex 2, p=Vertex 0, depth=2)\n",
      "trace of n3:  [<__main__.Vertex object at 0x1101cf6d8>, <__main__.Vertex object at 0x1101ad780>, <__main__.Vertex object at 0x1101adc88>]\n"
     ]
    }
   ],
   "source": [
    "test_get_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to get sample graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Vertex 0\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 1\n",
      "\t<-> Vertex 0\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 2\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 3\n",
      "================================================================================\n",
      "Vertex 3\n",
      "\t<-> Vertex 2\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "================================================================================\n",
      "Vertex 0\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 4\n",
      "\t<-> Vertex 6\n",
      "================================================================================\n",
      "Vertex 1\n",
      "\t<-> Vertex 0\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 2\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 3\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 4\n",
      "\t<-> Vertex 0\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 5\n",
      "================================================================================\n",
      "Vertex 5\n",
      "\t<-> Vertex 4\n",
      "\t<-> Vertex 6\n",
      "================================================================================\n",
      "Vertex 6\n",
      "\t<-> Vertex 0\n",
      "\t<-> Vertex 5\n"
     ]
    }
   ],
   "source": [
    "def get_sample_udgraph():\n",
    "    v0 = Vertex(0); v1 = Vertex(1); v2 = Vertex(2); v3 = Vertex(3);\n",
    "    v0.add_neighbors([v1, v2])\n",
    "    v1.add_neighbors([v0, v2])\n",
    "    v2.add_neighbors([v1, v3])\n",
    "    v3.add_neighbors([v2])\n",
    "    G = UndirectedGraph(vertices=[v0, v1, v2, v3])\n",
    "    \n",
    "    return G\n",
    "\n",
    "def get_sample_udgraph_1():\n",
    "    v0 = Vertex(0); v1 = Vertex(1); v2 = Vertex(2); v3 = Vertex(3);v4 = Vertex(4);\n",
    "    v0.add_neighbors([v1, v2, v4])\n",
    "    v1.add_neighbors([v0, v2])\n",
    "    v2.add_neighbors([v1, v3])\n",
    "    v3.add_neighbors([v2])\n",
    "    v4.add_neighbors([v0])\n",
    "\n",
    "    G = UndirectedGraph(vertices=[v0, v1, v2, v3, v4])\n",
    "    \n",
    "    return G\n",
    "\n",
    "def get_sample_udgraph_2():\n",
    "    # Construct grph\n",
    "    ## todo: better way to add neighbors to both vertices and edges\n",
    "    v0 = Vertex(0); v1 = Vertex(1); v2 = Vertex(2); v3 = Vertex(3); v4 = Vertex(4); v5 = Vertex(5); v6 = Vertex(6)\n",
    "\n",
    "    v0.add_neighbors([v1, v4, v6])\n",
    "    v1.add_neighbors([v0, v2])\n",
    "    v2.add_neighbors([v1, v3, v4])\n",
    "    v3.add_neighbors([v2])\n",
    "    v4.add_neighbors([v0, v2, v5])\n",
    "    v5.add_neighbors([v4, v6])\n",
    "    v6.add_neighbors([v0, v5])\n",
    "    V = [v0, v1, v2, v3, v4, v5, v6]\n",
    "    \n",
    "    G = UndirectedGraph(V)\n",
    "    \n",
    "    return G\n",
    "g1 = get_sample_udgraph()\n",
    "g2 =  get_sample_udgraph_2()\n",
    "\n",
    "g1.print_structure()\n",
    "\n",
    "print(\"+\"*80)\n",
    "g2.print_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Vertex, Edge, Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Vertex():# Construct some graph\n",
    "    ## todo: better way to add neighbors to both vertices and edges\n",
    "    v0 = Vertex(0); v1 = Vertex(1); v2 = Vertex(2); v3 = Vertex(3); v4 = Vertex(4); v5 = Vertex(5); v6 = Vertex(6)\n",
    "\n",
    "    v0.add_neighbors([v1, v4, v6])\n",
    "    v1.add_neighbors([v0, v2])\n",
    "    v2.add_neighbors([v1, v3, v4])\n",
    "    v3.add_neighbors([v2])\n",
    "    v4.add_neighbors([v0, v2, v5])\n",
    "    v5.add_neighbors([v4, v6])\n",
    "    v6.add_neighbors([v0, v5])\n",
    "    V = set([v0, v1, v2, v3, v4, v5, v6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_edge():\n",
    "    e01 = UndirectedEdge(v0,v1); print(e01)\n",
    "    e10 = UndirectedEdge(v1,v0); print(e10)\n",
    "    print(\"e01 == e10: \", e01 == e10)\n",
    "    e02 = UndirectedEdge(v0,v2); print(e02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e01: Edge(0 -> 1)\n",
      "e02: Edge(0 -> 2)\n",
      "e01==e02: False\n",
      "e01==e10: False\n"
     ]
    }
   ],
   "source": [
    "def test_DirectedEdge():\n",
    "    v0 = Vertex(0); v1 = Vertex(1); v2 = Vertex(2)\n",
    "    \n",
    "    e01 = DirectedEdge(v0, v1)\n",
    "    e02 = DirectedEdge(v0, v2)\n",
    "    e10 = DirectedEdge(v1, v0)\n",
    "    print(f\"e01: {e01}\")\n",
    "    print(f\"e02: {e02}\")\n",
    "    print(f\"e01==e02: {e01==e02}\")\n",
    "    print(f\"e01==e10: {e01==e10}\")\n",
    "\n",
    "test_DirectedEdge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges:\n",
      "Edge(0 <-> 1)\n",
      "Edge(2 <-> 3)\n",
      "Edge(0 <-> 2)\n",
      "Edge(1 <-> 2)\n",
      "================================================================================\n",
      "Vertex 0\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 1\n",
      "\t<-> Vertex 0\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 2\n",
      "\t<-> Vertex 3\n",
      "================================================================================\n",
      "Vertex 3\n",
      "\t<-> Vertex 2\n",
      "Vertex 0 True\n",
      "Vertex 1 True\n",
      "Vertex 2 True\n",
      "Vertex 3 True\n",
      "dummy in?:  False\n"
     ]
    }
   ],
   "source": [
    "def test_UndirectedGraph():\n",
    "#     g1 = Graph(vertices=[v0,v1,v2,v3])\n",
    "    v0 = Vertex(0); v1 = Vertex(1); v2 = Vertex(2); v3 = Vertex(3);\n",
    "    v0.add_neighbors([v1, v2])\n",
    "    v1.add_neighbors([v0, v2])\n",
    "    v2.add_neighbors([v3])\n",
    "    v3.add_neighbors([v2])\n",
    "    g1 = UndirectedGraph(vertices=[v0, v1, v2, v3])\n",
    "\n",
    "    # print([n.vid for n in g1.neighbors(v3)])\n",
    "    print(\"Edges:\")\n",
    "    g1.print_edges()\n",
    "    \n",
    "    # print adjacent edges\n",
    "    for vid, v in g1.V.items():\n",
    "        print(\"=\"*80)\n",
    "        print(v)\n",
    "        v.print_neighbors()\n",
    "              \n",
    "    # check has_vertex and has_edge\n",
    "    for vid, v in g1.V.items():\n",
    "        print(v, g1.has_vertex(v))\n",
    "    dummy = Vertex(0)\n",
    "    dummy.add_neighbors([v3])\n",
    "    print(\"dummy in?: \", g1.has_vertex(dummy))\n",
    "    \n",
    "test_UndirectedGraph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "k=3\n",
      "================================================================================\n",
      "Vertex 0\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 1\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 2\n",
      "\n",
      "\n",
      "k=4\n",
      "================================================================================\n",
      "Vertex 0\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 3\n",
      "================================================================================\n",
      "Vertex 1\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 3\n",
      "================================================================================\n",
      "Vertex 2\n",
      "\t<-> Vertex 3\n",
      "================================================================================\n",
      "Vertex 3\n",
      "\n",
      "\n",
      "k=5\n",
      "================================================================================\n",
      "Vertex 0\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 1\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 2\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 3\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 4\n",
      "\n",
      "\n",
      "k=6\n",
      "================================================================================\n",
      "Vertex 0\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "\t<-> Vertex 5\n",
      "================================================================================\n",
      "Vertex 1\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "\t<-> Vertex 5\n",
      "================================================================================\n",
      "Vertex 2\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "\t<-> Vertex 5\n",
      "================================================================================\n",
      "Vertex 3\n",
      "\t<-> Vertex 4\n",
      "\t<-> Vertex 5\n",
      "================================================================================\n",
      "Vertex 4\n",
      "\t<-> Vertex 5\n",
      "================================================================================\n",
      "Vertex 5\n"
     ]
    }
   ],
   "source": [
    "def test_DAG():\n",
    "    for k in range(3,7):\n",
    "        print('\\n\\nk={}'.format(k))\n",
    "        dag = DAG(k)\n",
    "        dag.print_structure()\n",
    "test_DAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Path of length 1\n",
      "Node(0, p=None, depth=1)\n",
      "================================================================================\n",
      "Paths of length 2\n",
      "Node(1, p=0, depth=2) [1, 0]\n",
      "Node(2, p=0, depth=2) [2, 0]\n",
      "Node(4, p=0, depth=2) [4, 0]\n",
      "================================================================================\n",
      "Paths of length 3\n",
      "Node(3, p=2, depth=3) [3, 2, 0]\n",
      "Node(4, p=2, depth=3) [4, 2, 0]\n",
      "Node(5, p=4, depth=3) [5, 4, 0]\n",
      "================================================================================\n",
      "Paths of length 4\n",
      "Node(5, p=4, depth=4) [5, 4, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "def test_Node():\n",
    "    n0 = Node(0, parent=None)\n",
    "    n1 = Node(1, parent=n0)\n",
    "    n2 = Node(2, parent=n0)\n",
    "\n",
    "    n3 = Node(3, parent=n2)\n",
    "    print(\"n0: \", n0)\n",
    "    print(\"n1: \", n1)\n",
    "    print(\"n2: \", n2)\n",
    "    print(\"n3: \", n3)\n",
    "    \n",
    "def test_Node_2():\n",
    "    nprint(\"Path of length 1\")\n",
    "    n0 = Node(0, parent=None);print(n0)\n",
    "    \n",
    "    nprint(\"Paths of length 2\")\n",
    "    n1 = Node(1, parent=n0);print(n1, get_trace(n1))\n",
    "    n2 = Node(2, parent=n0);print(n2, get_trace(n2))\n",
    "    n4 = Node(4, parent=n0);print(n4, get_trace(n4))\n",
    "\n",
    "    nprint(\"Paths of length 3\")\n",
    "    n3 = Node(3, parent=n2);print(n3, get_trace(n3))\n",
    "    n5 = Node(4, parent=n2);print(n5, get_trace(n5))\n",
    "    n6 = Node(5, parent=n4);print(n6, get_trace(n6))\n",
    "\n",
    "    nprint(\"Paths of length 4\")\n",
    "    n7 = Node(5, parent=n5);print(n7, get_trace(n7))\n",
    "           \n",
    "# test_Node()\n",
    "test_Node_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Graph Search Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Depth First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS(G, start_vid, goal_vid,\n",
    "       verbose=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - G (Graph)\n",
    "        - Has a method `G.neighbors(v)` which returns a list of vertex ids neighboring vertex `v`\n",
    "    - start_vid (int: Vertex id): vertex id of the start vertex in G\n",
    "    - goal_vid (int: Vertex id): vertex id of the goal vertex in G\n",
    "    \"\"\"\n",
    "    assert start_vid in G.V, \"start node not found in Graph\"\n",
    "    assert goal_vid in G.V, \"goal node not found in Graph\"\n",
    "    \n",
    "    S = Node(vid=start_vid, parent=None)\n",
    "    Q = [S] # Queue that is actually a stack.  List of Node objs\n",
    "    Expanded = set() # a set of integers for vertex ids\n",
    "    while len(Q) > 0:\n",
    "        N = Q.pop(0)\n",
    "        if N.vid == goal_vid:\n",
    "            return get_trace(N)\n",
    "        \n",
    "        # Expand N and add its children nodes that haven't been explored yet\n",
    "        Expanded.add(N.vid)\n",
    "        cnodes = [Node(vid=c.vid, parent=N) for c in G.get_neighbors(N.vid) if c.vid not in Expanded]\n",
    "        cnodes.sort(key=lambda n: n.vid)\n",
    "        Q = cnodes + Q # prepend the children nodes\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Expanding: \", N, \"...\")\n",
    "            print(\"Updated stack: \", [node.vid for node in Q])\n",
    "            print(\"So far, Expanded: \", Expanded)\n",
    "\n",
    "#         pdb.set_trace()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Vertex 0\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 1\n",
      "\t<-> Vertex 0\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 2\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 3\n",
      "================================================================================\n",
      "Vertex 3\n",
      "\t<-> Vertex 2\n",
      "================================================================================\n",
      "Vertex 4\n",
      "\t<-> Vertex 0\n"
     ]
    }
   ],
   "source": [
    "G = get_sample_udgraph_1()\n",
    "G.print_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFS(G, 0, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. kBFS\n",
    "Find all paths of length $k$ starting from a vertex $V$ in graph $G$\n",
    "- If $G$ is a DAG with $V = {0,1,...,n-1}$, then this is equivalent to finding all possibile combinations of $n \\choose k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "come-back"
    ]
   },
   "outputs": [],
   "source": [
    "def kBFS(G, start_vid, k, verbose=False):\n",
    "    \"\"\"\n",
    "    Given a graph G=(V,E), find all paths of length `k` starting from vertex `start_vid`\n",
    "    \n",
    "    Args:\n",
    "    - G (Graph)\n",
    "    - start_vid (int): start vertex to compute the path and path length\n",
    "    - k (int): length of the paths we are looking for\n",
    "    \n",
    "    Returns:\n",
    "    - collection (list): a list of sets where each set contains `k` integers indicating \n",
    "                         vertices on the path of length `k`          \n",
    "    \"\"\"\n",
    "    assert start_vid in G.V, \"start node not in the graph\"\n",
    "    \n",
    "    S = Node(vid = start_vid, parent=None)\n",
    "    Q = [S] # Queue containing Node objects\n",
    "#     Expanded = set() # a set of integers for vertex ids visited/expanded \n",
    "## 3/26/2019 (w) Keeping track of Expanded node is erronous for BFS\n",
    "    collection = []\n",
    "    while len(Q) > 0: \n",
    "        N = Q.pop(0)\n",
    "        \n",
    "        # check if the search goal is met\n",
    "        if N.path_len == k:\n",
    "            collection.append(frozenset(get_trace(N)))\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Woohoo. Found a path of length {}: {}\".format(k, N))\n",
    "                print(\"\\t {}\".format(get_trace(N)))\n",
    "        else:\n",
    "            # This node needs to be expanded, so that its children paths can be \n",
    "            # explored further\n",
    "            # 3/26/2019 (W): Expanded list is erronous for BFS\n",
    "#             Expanded.add(N.vid)\n",
    "            \n",
    "            # 3/26/2019 (W): Found a bug for `nCn`\n",
    "            # Below is wrong! nCn will return empty.\n",
    "#             cnodes = [Node(vid=v.vid, parent=N) for v in G.get_neighbors(N.vid) if v.vid not in Expanded]\n",
    "            # Instead exclude any node in this node's path trace from the children list\n",
    "            # Better to implement `get_children` method for Node class\n",
    "            cnodes = [Node(vid=v.vid, parent=N) for v in G.get_neighbors(N.vid) if v.vid not in get_trace(N)]\n",
    "        \n",
    "            # Give order by vertex id\n",
    "            cnodes.sort(key=lambda n:n.vid)\n",
    "            Q.extend(cnodes) # add the children nodes to the end of queue (BFS)\n",
    "            \n",
    "            if verbose:\n",
    "                nprint(\"Expanding: \", N, \"...\")\n",
    "                print(\"Updated queue: \", [node.vid for node in Q])\n",
    "    \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 3. $nCk$ implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCk(n, k, **kwargs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - n (int): number of elements in the full list \n",
    "    - k (int): number of items to choose\n",
    "    \n",
    "    Returns:\n",
    "    - collections (list): a list of sets where each set contains `k` integers \n",
    "        indicating the ids of selected vertices\n",
    "        \n",
    "    \"\"\"\n",
    "    dag = DAG(n)\n",
    "#     pdb.set_trace()\n",
    "    collections = []\n",
    "    for start_vid in range(n):\n",
    "        collections.extend(kBFS(dag, start_vid, k, **kwargs))\n",
    "    return collections\n",
    "                           \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - kBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kBFS_1():\n",
    "    G = get_sample_graph()\n",
    "    G.print_structure()\n",
    "    \n",
    "    result = kBFS(G, 0, 2, verbose=True)\n",
    "    \n",
    "def test_kBFS_2():\n",
    "    G = get_sample_graph()\n",
    "    G.print_structure()\n",
    "    \n",
    "    result = kBFS(G, 0, 3, verbose=True)\n",
    "    \n",
    "def test_kBFS_3():\n",
    "    G = get_sample_graph()\n",
    "    G.print_structure()\n",
    "    \n",
    "    result = kBFS(G, 0, 4, verbose=True)\n",
    "    \n",
    "def test_kBFS_4():\n",
    "    G = get_sample_graph()\n",
    "    G.print_structure()\n",
    "    \n",
    "    result = kBFS(G, 0, 5, verbose=True)  \n",
    "    print(result)\n",
    "\n",
    "# test_kBFS_1()\n",
    "# test_kBFS_2()\n",
    "# test_kBFS_3()\n",
    "# test_kBFS_4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Vertex 0\n",
      "\t<-> Vertex 1\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 1\n",
      "\t<-> Vertex 2\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 2\n",
      "\t<-> Vertex 3\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 3\n",
      "\t<-> Vertex 4\n",
      "================================================================================\n",
      "Vertex 4\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=None, depth=1)\n",
      "...\n",
      "Updated queue:  [4]\n",
      "Woohoo. Found a path of length 2: Node(4, p=3, depth=2)\n",
      "\t [4, 3]\n"
     ]
    }
   ],
   "source": [
    "def test_kBFS_DAG_Node_1():\n",
    "    n = 5 # number of vertices in the graph\n",
    "    dag = DAG(n)\n",
    "    dag.print_structure()\n",
    "    k = 2\n",
    "    start_vid = 3\n",
    "    kBFS(dag, start_vid, k, verbose=True)\n",
    "test_kBFS_DAG_Node_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Expanding: \n",
      "Node(0, p=None, depth=1)\n",
      "...\n",
      "Updated queue:  [1, 2, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(1, p=0, depth=2)\n",
      "...\n",
      "Updated queue:  [2, 3, 4, 2, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(2, p=0, depth=2)\n",
      "...\n",
      "Updated queue:  [3, 4, 2, 3, 4, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=0, depth=2)\n",
      "...\n",
      "Updated queue:  [4, 2, 3, 4, 3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=0, depth=2)\n",
      "...\n",
      "Updated queue:  [2, 3, 4, 3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(2, p=1, depth=3)\n",
      "...\n",
      "Updated queue:  [3, 4, 3, 4, 4, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=1, depth=3)\n",
      "...\n",
      "Updated queue:  [4, 3, 4, 4, 3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=1, depth=3)\n",
      "...\n",
      "Updated queue:  [3, 4, 4, 3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=2, depth=3)\n",
      "...\n",
      "Updated queue:  [4, 4, 3, 4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=2, depth=3)\n",
      "...\n",
      "Updated queue:  [4, 3, 4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=3)\n",
      "...\n",
      "Updated queue:  [3, 4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=2, depth=4)\n",
      "...\n",
      "Updated queue:  [4, 4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=2, depth=4)\n",
      "...\n",
      "Updated queue:  [4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=4)\n",
      "...\n",
      "Updated queue:  [4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=4)\n",
      "...\n",
      "Updated queue:  [4]\n",
      "Woohoo. Found a path of length 5: Node(4, p=3, depth=5)\n",
      "\t [4, 3, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def test_kBFS_DAG_Node_2():\n",
    "    n = 5 # number of vertices in the graph\n",
    "    dag = DAG(n); #dag.print_structure()\n",
    "    \n",
    "    k = 5\n",
    "    start_vid = 0\n",
    "    kBFS(dag, start_vid, k, verbose=True)\n",
    "test_kBFS_DAG_Node_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - nCk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "come-back"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Expanding: \n",
      "Node(0, p=None, depth=1)\n",
      "...\n",
      "Updated queue:  [1, 2, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(1, p=0, depth=2)\n",
      "...\n",
      "Updated queue:  [2, 3, 4, 2, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(2, p=0, depth=2)\n",
      "...\n",
      "Updated queue:  [3, 4, 2, 3, 4, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=0, depth=2)\n",
      "...\n",
      "Updated queue:  [4, 2, 3, 4, 3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=0, depth=2)\n",
      "...\n",
      "Updated queue:  [2, 3, 4, 3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(2, p=1, depth=3)\n",
      "...\n",
      "Updated queue:  [3, 4, 3, 4, 4, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=1, depth=3)\n",
      "...\n",
      "Updated queue:  [4, 3, 4, 4, 3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=1, depth=3)\n",
      "...\n",
      "Updated queue:  [3, 4, 4, 3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=2, depth=3)\n",
      "...\n",
      "Updated queue:  [4, 4, 3, 4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=2, depth=3)\n",
      "...\n",
      "Updated queue:  [4, 3, 4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=3)\n",
      "...\n",
      "Updated queue:  [3, 4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=2, depth=4)\n",
      "...\n",
      "Updated queue:  [4, 4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=2, depth=4)\n",
      "...\n",
      "Updated queue:  [4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=4)\n",
      "...\n",
      "Updated queue:  [4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=4)\n",
      "...\n",
      "Updated queue:  [4]\n",
      "Woohoo. Found a path of length 5: Node(4, p=3, depth=5)\n",
      "\t [4, 3, 2, 1, 0]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(1, p=None, depth=1)\n",
      "...\n",
      "Updated queue:  [2, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(2, p=1, depth=2)\n",
      "...\n",
      "Updated queue:  [3, 4, 3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=1, depth=2)\n",
      "...\n",
      "Updated queue:  [4, 3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=1, depth=2)\n",
      "...\n",
      "Updated queue:  [3, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=2, depth=3)\n",
      "...\n",
      "Updated queue:  [4, 4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=2, depth=3)\n",
      "...\n",
      "Updated queue:  [4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=3)\n",
      "...\n",
      "Updated queue:  [4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=4)\n",
      "...\n",
      "Updated queue:  []\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(2, p=None, depth=1)\n",
      "...\n",
      "Updated queue:  [3, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=2, depth=2)\n",
      "...\n",
      "Updated queue:  [4, 4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=2, depth=2)\n",
      "...\n",
      "Updated queue:  [4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=3)\n",
      "...\n",
      "Updated queue:  []\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(3, p=None, depth=1)\n",
      "...\n",
      "Updated queue:  [4]\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=3, depth=2)\n",
      "...\n",
      "Updated queue:  []\n",
      "================================================================================\n",
      "Expanding: \n",
      "Node(4, p=None, depth=1)\n",
      "...\n",
      "Updated queue:  []\n",
      "================================================================================\n",
      "Done: n=5, k=5\n",
      "[frozenset({0, 1, 2, 3, 4})]\n"
     ]
    }
   ],
   "source": [
    "def test_nCk_1():\n",
    "    n, k = 5, 2\n",
    "    collections = nCk(n,k, verbose=True)\n",
    "    nprint(\"Done\")\n",
    "    pprint(collections)\n",
    "\n",
    "def test_nCk_2():\n",
    "    n, k = 5, 3\n",
    "    collections = nCk(n,k, verbose=True)\n",
    "    nprint(\"Done: n={}, k={}\".format(n,k))\n",
    "    pprint(collections)\n",
    "    \n",
    "def test_nCk_3():\n",
    "    n, k = 5, 5\n",
    "    collections = nCk(n,k, verbose=True)\n",
    "    nprint(\"Done: n={}, k={}\".format(n,k))\n",
    "    pprint(collections)\n",
    "test_nCk_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - CombNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Root:\n",
      "CombNode(frozenset({0, 1}), p=None, level=1), Remaining: [2 3]\n",
      "================================================================================\n",
      "Child1: \n",
      "CombNode(frozenset({2, 3}), p=frozenset({0, 1}), level=2), Remaining: []\n",
      "================================================================================\n",
      "Check its parent node:\n",
      "CombNode(frozenset({0, 1}), p=None, level=1), Remaining: [2 3]\n",
      "================================================================================\n",
      "Traceback: \n",
      "[frozenset({2, 3}), frozenset({0, 1})]\n"
     ]
    }
   ],
   "source": [
    "def test_CombNode():\n",
    "    orig_list = [0,1,2,3]\n",
    "    binsizes = (2,2)\n",
    "    vidset = set([0,1]) # len is equal to binsizes[0]\n",
    "\n",
    "    n0 = CombNode(vidset, None, orig_list, binsizes)\n",
    "    nprint(\"Root:\", n0)\n",
    "\n",
    "    children = n0.get_children()\n",
    "    child = children[0]\n",
    "    nprint(\"Child1: \", child)\n",
    "    \n",
    "    nprint(\"Check its parent node:\")\n",
    "    print(child.parent)\n",
    "    \n",
    "    nprint(\"Traceback: \",get_trace(child))\n",
    "test_CombNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Root:\n",
      "CombNode(frozenset({0, 1}), p=None, level=1), Remaining: [2 3 4]\n",
      "================================================================================\n",
      "Child 0\n",
      "CombNode(frozenset({2, 3, 4}), p=frozenset({0, 1}), level=2), Remaining: []\n",
      "================================================================================\n",
      "Sample child: \n",
      "CombNode(frozenset({2, 3, 4}), p=frozenset({0, 1}), level=2), Remaining: []\n",
      "================================================================================\n",
      "Check its parent node:\n",
      "CombNode(frozenset({0, 1}), p=None, level=1), Remaining: [2 3 4]\n",
      "================================================================================\n",
      "Traceback: \n",
      "[frozenset({2, 3, 4}), frozenset({0, 1})]\n"
     ]
    }
   ],
   "source": [
    "def test_CombNode_2():\n",
    "    orig_list = [0,1,2,3,4]\n",
    "    binsizes = (2,3)\n",
    "    vidset = set([0,1]) # len is equal to binsizes[0]\n",
    "\n",
    "    n0 = CombNode(vidset, None, orig_list, binsizes)\n",
    "    nprint(\"Root:\", n0)\n",
    "    children = n0.get_children()\n",
    "    for i, c in enumerate(children):\n",
    "        nprint(f\"Child {i}\", c)\n",
    "    child = children[0]\n",
    "    nprint(\"Sample child: \", child)\n",
    "\n",
    "    nprint(\"Check its parent node:\")\n",
    "    print(child.parent)\n",
    "\n",
    "    nprint(\"Traceback: \",get_trace(child))\n",
    "test_CombNode_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Root:\n",
      "CombNode(frozenset({0, 1}), p=None, level=1), Remaining: [2 3 4]\n",
      "================================================================================\n",
      "Child 0\n",
      "CombNode(frozenset({2, 3}), p=frozenset({0, 1}), level=2), Remaining: [4]\n",
      "================================================================================\n",
      "Child 1\n",
      "CombNode(frozenset({2, 4}), p=frozenset({0, 1}), level=2), Remaining: [3]\n",
      "================================================================================\n",
      "Child 2\n",
      "CombNode(frozenset({3, 4}), p=frozenset({0, 1}), level=2), Remaining: [2]\n",
      "================================================================================\n",
      "Child Sample: \n",
      "CombNode(frozenset({2, 3}), p=frozenset({0, 1}), level=2), Remaining: [4]\n",
      "================================================================================\n",
      "Check its parent node:\n",
      "CombNode(frozenset({0, 1}), p=None, level=1), Remaining: [2 3 4]\n",
      "================================================================================\n",
      "Traceback: \n",
      "[frozenset({2, 3}), frozenset({0, 1})]\n",
      "================================================================================\n",
      "Grandchild 1\n",
      "CombNode(frozenset({4}), p=frozenset({2, 3}), level=3), Remaining: []\n",
      "================================================================================\n",
      "Grandchild Traceback: \n",
      "[frozenset({4}), frozenset({2, 3}), frozenset({0, 1})]\n",
      "================================================================================\n",
      "GGchild: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def test_CombNode_3():\n",
    "    \"\"\" \n",
    "    Check three level of CombNode expansion: Root->child->grandchild\n",
    "    \"\"\"\n",
    "    orig_list = [0,1,2,3,4]\n",
    "    orig_list = np.array(orig_list)\n",
    "\n",
    "    binsizes = (2,2,1)\n",
    "    vidset = set(orig_list[ [0,1]] ) # len is equal to binsizes[0]\n",
    "\n",
    "    n0 = CombNode(vidset, None, orig_list, binsizes)\n",
    "    nprint(\"Root:\", n0)\n",
    "\n",
    "    children = n0.get_children()\n",
    "    for i, c in enumerate(children):\n",
    "        nprint(f\"Child {i}\", c)\n",
    "        \n",
    "    child = children[0]\n",
    "    nprint(\"Child Sample: \", child)\n",
    "\n",
    "    nprint(\"Check its parent node:\")\n",
    "    print(child.parent)\n",
    "    nprint(\"Traceback: \",get_trace(child))\n",
    "    \n",
    "    grandchildren = child.get_children()\n",
    "    grandchild = grandchildren[0]\n",
    "    nprint(\"Grandchild 1\", grandchild)\n",
    "    nprint(\"Grandchild Traceback: \",get_trace(grandchild))\n",
    "    \n",
    "    # Grandchildren has no child\n",
    "    ggchild = grandchild.get_children()\n",
    "    nprint(\"GGchild: \", ggchild)\n",
    "\n",
    "test_CombNode_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Root:\n",
      "CombNode(frozenset({'zero', 'one'}), p=None, level=1), Remaining: ['two' 'three' 'four']\n",
      "================================================================================\n",
      "Child 0\n",
      "CombNode(frozenset({'three', 'two'}), p=frozenset({'zero', 'one'}), level=2), Remaining: ['four']\n",
      "================================================================================\n",
      "Child 1\n",
      "CombNode(frozenset({'four', 'two'}), p=frozenset({'zero', 'one'}), level=2), Remaining: ['three']\n",
      "================================================================================\n",
      "Child 2\n",
      "CombNode(frozenset({'four', 'three'}), p=frozenset({'zero', 'one'}), level=2), Remaining: ['two']\n",
      "================================================================================\n",
      "Child Sample: \n",
      "CombNode(frozenset({'three', 'two'}), p=frozenset({'zero', 'one'}), level=2), Remaining: ['four']\n",
      "================================================================================\n",
      "Check its parent node:\n",
      "CombNode(frozenset({'zero', 'one'}), p=None, level=1), Remaining: ['two' 'three' 'four']\n",
      "================================================================================\n",
      "Traceback: \n",
      "[frozenset({'three', 'two'}), frozenset({'zero', 'one'})]\n",
      "================================================================================\n",
      "Grandchild 1\n",
      "CombNode(frozenset({'four'}), p=frozenset({'three', 'two'}), level=3), Remaining: []\n",
      "================================================================================\n",
      "Grandchild Traceback: \n",
      "[frozenset({'four'}), frozenset({'three', 'two'}), frozenset({'zero', 'one'})]\n",
      "================================================================================\n",
      "GGchild: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def test_CombNode_4():\n",
    "    \"\"\" \n",
    "    Check three level of CombNode expansion: Root->child->grandchild\n",
    "    \"\"\"\n",
    "    orig_list = [\"zero\",\"one\", \"two\", \"three\", \"four\"]\n",
    "    orig_list = np.array(orig_list)\n",
    "    binsizes = (2,2,1)\n",
    "    vidset = set(orig_list[ [0,1]] ) # len is equal to binsizes[0]\n",
    "    \n",
    "    n0 = CombNode(vidset, None, orig_list, binsizes)\n",
    "    nprint(\"Root:\", n0)\n",
    "\n",
    "    children = n0.get_children()\n",
    "    for i, c in enumerate(children):\n",
    "        nprint(f\"Child {i}\", c)\n",
    "        \n",
    "    child = children[0]\n",
    "    nprint(\"Child Sample: \", child)\n",
    "\n",
    "    nprint(\"Check its parent node:\")\n",
    "    print(child.parent)\n",
    "    nprint(\"Traceback: \",get_trace(child))\n",
    "    \n",
    "    grandchildren = child.get_children()\n",
    "    grandchild = grandchildren[0]\n",
    "    nprint(\"Grandchild 1\", grandchild)\n",
    "    nprint(\"Grandchild Traceback: \",get_trace(grandchild))\n",
    "    \n",
    "    # Grandchildren has no child\n",
    "    ggchild = grandchild.get_children()\n",
    "    nprint(\"GGchild: \", ggchild)\n",
    "test_CombNode_4()\n",
    "\n",
    "def test_CombNode_5():\n",
    "    orig_list = np.array([\"zero\",\"one\", \"two\", \"three\", \"four\"])\n",
    "\n",
    "    # first get the level0 and initiate the queue\n",
    "    print('orig_list: ', orig_list)\n",
    "    binsize = [1,1,3]\n",
    "    print('binsize: ', binsize)\n",
    "\n",
    "    n = len(orig_list)\n",
    "    level0_idxset_list = nCk(n,binsize[0])\n",
    "    level0_vidset_list = [ set(orig_list[list(idxset)])  for idxset in level0_idxset_list ] \n",
    "    pprint(level0_vidset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Root:\n",
      "CombNode(frozenset({'zero', 'one'}), p=None, level=1), Remaining: ['two' 'three' 'four']\n"
     ]
    }
   ],
   "source": [
    "# orig_list = [0,1,2,3,4]\n",
    "orig_list = [\"zero\",\"one\", \"two\", \"three\", \"four\"]\n",
    "orig_list = np.array(orig_list)\n",
    "\n",
    "binsizes = (2,2,1)\n",
    "vidset = set(orig_list[ [0,1]] ) # len is equal to binsizes[0]\n",
    "\n",
    "n0 = CombNode(vidset, None, orig_list, binsizes)\n",
    "nprint(\"Root:\", n0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Child 0\n",
      "CombNode(frozenset({'three', 'two'}), p=frozenset({'zero', 'one'}), level=2), Remaining: ['four']\n",
      "================================================================================\n",
      "Child 1\n",
      "CombNode(frozenset({'four', 'two'}), p=frozenset({'zero', 'one'}), level=2), Remaining: ['three']\n",
      "================================================================================\n",
      "Child 2\n",
      "CombNode(frozenset({'four', 'three'}), p=frozenset({'zero', 'one'}), level=2), Remaining: ['two']\n"
     ]
    }
   ],
   "source": [
    "children = n0.get_children()\n",
    "for i, c in enumerate(children):\n",
    "    nprint(f\"Child {i}\", c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Child Sample: \n",
      "CombNode(frozenset({'three', 'two'}), p=frozenset({'zero', 'one'}), level=2), Remaining: ['four']\n",
      "================================================================================\n",
      "Check its parent node:\n",
      "CombNode(frozenset({'zero', 'one'}), p=None, level=1), Remaining: ['two' 'three' 'four']\n",
      "================================================================================\n",
      "Traceback: \n",
      "[frozenset({'three', 'two'}), frozenset({'zero', 'one'})]\n"
     ]
    }
   ],
   "source": [
    "child = children[0]\n",
    "nprint(\"Child Sample: \", child)\n",
    "\n",
    "nprint(\"Check its parent node:\")\n",
    "print(child.parent)\n",
    "\n",
    "nprint(\"Traceback: \",get_trace(child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Grandchild 1\n",
      "CombNode(frozenset({'four'}), p=frozenset({'three', 'two'}), level=3), Remaining: []\n",
      "================================================================================\n",
      "Grandchild Traceback: \n",
      "[frozenset({'four'}), frozenset({'three', 'two'}), frozenset({'zero', 'one'})]\n",
      "================================================================================\n",
      "GGchild: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "grandchildren = child.get_children()\n",
    "grandchild = grandchildren[0]\n",
    "nprint(\"Grandchild 1\", grandchild)\n",
    "nprint(\"Grandchild Traceback: \",get_trace(grandchild))\n",
    "\n",
    "# Grandchildren has no child\n",
    "ggchild = grandchild.get_children()\n",
    "nprint(\"GGchild: \", ggchild)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Finally, let's get all groupings\n",
    "Apply `DFS` on `CombNode`s to get all possible groupings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_combs(orig_list, binsizes, verbose=False):\n",
    "    \n",
    "    # First, get the level0 nodes and initiate the queue with them\n",
    "    n = len(orig_list)\n",
    "    search_depth = len(binsizes)\n",
    "    level0_idxset_list = nCk(n, binsizes[0])\n",
    "    level0_vidset_list = [ set(orig_list[list(idxset)])  for idxset in level0_idxset_list ]\n",
    "    level0_nodes = [CombNode(vid=vidset, parent=None, orig_list=orig_list, binsizes=binsizes)\n",
    "                   for vidset in level0_vidset_list]\n",
    "    Q = level0_nodes\n",
    "    \n",
    "    if verbose: \n",
    "        print('orig_list: ', orig_list)\n",
    "        print('binsizes: ', binsizes)\n",
    "        nprint(f\"Initial Queue of nodes [{len(level0_nodes)}]: \\n\", *Q)\n",
    "        nprint()\n",
    "    \n",
    "    # Collect the possible combinations using DFS\n",
    "    collection = set([])\n",
    "    while len(Q) > 0:\n",
    "        N = Q.pop(0)\n",
    "        \n",
    "        # this is better since it can handle binsizes that does not \n",
    "        # necessarily add upto the len(org_list) \n",
    "        if N.depth == search_depth: \n",
    "            collection.add(frozenset(get_trace(N)))\n",
    "        else:\n",
    "            children = N.get_children()\n",
    "            \n",
    "            ## debugging\n",
    "            print(N)\n",
    "            print('num children: ', len(children))\n",
    "            print(children[0])\n",
    "            temp = children[0]\n",
    "            temp.get_children(verbose=True)\n",
    "#             pdb.set_trace()\n",
    "            ## end of debugging\n",
    "\n",
    "            # add to the top of stack\n",
    "            Q = children + Q\n",
    "    if verbose:\n",
    "        print(\"Num of all possible combs: \", len(collection)) \n",
    "        nprint(\"\\nCollection: \", *collection, header=False)\n",
    "    \n",
    "    return collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_list:  [0 1 2 3 4]\n",
      "binsizes:  [2, 2, 1]\n",
      "================================================================================\n",
      "Initial Queue of nodes [10]: \n",
      "\n",
      "CombNode(frozenset({0, 1}), p=None, level=1), Remaining: [2 3 4]\n",
      "CombNode(frozenset({0, 2}), p=None, level=1), Remaining: [1 3 4]\n",
      "CombNode(frozenset({0, 3}), p=None, level=1), Remaining: [1 2 4]\n",
      "CombNode(frozenset({0, 4}), p=None, level=1), Remaining: [1 2 3]\n",
      "CombNode(frozenset({1, 2}), p=None, level=1), Remaining: [0 3 4]\n",
      "CombNode(frozenset({1, 3}), p=None, level=1), Remaining: [0 2 4]\n",
      "CombNode(frozenset({1, 4}), p=None, level=1), Remaining: [0 2 3]\n",
      "CombNode(frozenset({2, 3}), p=None, level=1), Remaining: [0 1 4]\n",
      "CombNode(frozenset({2, 4}), p=None, level=1), Remaining: [0 1 3]\n",
      "CombNode(frozenset({3, 4}), p=None, level=1), Remaining: [0 1 2]\n",
      "================================================================================\n",
      "CombNode(frozenset({0, 1}), p=None, level=1), Remaining: [2 3 4]\n",
      "num children:  3\n",
      "CombNode(frozenset({2, 3}), p=frozenset({0, 1}), level=2), Remaining: [4]\n",
      "remaining elements:  [4]\n",
      "child binsize:  1\n",
      "idxset_list:  [frozenset({0})]\n",
      "vidset_list:  [{4}]\n",
      "> <ipython-input-43-ee58c8657d51>(41)get_all_combs()\n",
      "-> Q = children + Q\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-abd100126866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresult2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_combs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinsizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest_get_all_combs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-abd100126866>\u001b[0m in \u001b[0;36mtest_get_all_combs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     binsizes test 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbinsizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresult2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_combs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinsizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest_get_all_combs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-ee58c8657d51>\u001b[0m in \u001b[0;36mget_all_combs\u001b[0;34m(orig_list, binsizes, verbose)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# add to the top of stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchildren\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num of all possible combs: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-ee58c8657d51>\u001b[0m in \u001b[0;36mget_all_combs\u001b[0;34m(orig_list, binsizes, verbose)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# add to the top of stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchildren\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num of all possible combs: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai-cpu/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai-cpu/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_get_all_combs():\n",
    "#     orig_list = np.array(['zero', 'one', 'two', 'three', 'four'])\n",
    "    orig_list = np.array(range(5))\n",
    "\n",
    "    #binsizes test 1\n",
    "#     binsizes = [1,1,3]\n",
    "#     result1 = get_all_combs(orig_list, binsizes, True)\n",
    "    \n",
    "#     binsizes test 2\n",
    "    binsizes = [2,2,1]\n",
    "    result2 = get_all_combs(orig_list, binsizes, True)\n",
    "    \n",
    "test_get_all_combs()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "tags": [
     "come-back"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_list:  [0 1 2 3 4 5 6]\n",
      "binsizes:  [1, 1, 5]\n",
      "================================================================================\n",
      "Initial Queue of nodes [7]: \n",
      "\n",
      "CombNode(frozenset({0}), p=None, level=1), Remaining: [1 2 3 4 5 6]\n",
      "CombNode(frozenset({1}), p=None, level=1), Remaining: [0 2 3 4 5 6]\n",
      "CombNode(frozenset({2}), p=None, level=1), Remaining: [0 1 3 4 5 6]\n",
      "CombNode(frozenset({3}), p=None, level=1), Remaining: [0 1 2 4 5 6]\n",
      "CombNode(frozenset({4}), p=None, level=1), Remaining: [0 1 2 3 5 6]\n",
      "CombNode(frozenset({5}), p=None, level=1), Remaining: [0 1 2 3 4 6]\n",
      "CombNode(frozenset({6}), p=None, level=1), Remaining: [0 1 2 3 4 5]\n",
      "================================================================================\n",
      "CombNode(frozenset({0}), p=None, level=1), Remaining: [1 2 3 4 5 6]\n",
      "num children:  6\n",
      "CombNode(frozenset({1}), p=frozenset({0}), level=2), Remaining: [2 3 4 5 6]\n",
      "> <ipython-input-222-7eee86332bb6>(36)get_all_combs()\n",
      "-> Q = children + Q\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  children[0].get_children()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  temp = children[0]\n",
      "(Pdb)  print(temp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombNode(frozenset({1}), p=frozenset({0}), level=2), Remaining: [2 3 4 5 6]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  temp.depth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  temp.get_children(verbose=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining elements:  [2 3 4 5 6]\n",
      "child binsize:  5\n",
      "idxset_list:  []\n",
      "vidset_list:  []\n",
      "[]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  nCk(5,5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-348a52701b29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     binsizes = [2,2,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     result2 = get_all_combs(orig_list, binsizes, True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_get_all_combs_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-223-348a52701b29>\u001b[0m in \u001b[0;36mtest_get_all_combs_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0morig_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbinsizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_combs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinsizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     binsizes = [2,2,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-222-7eee86332bb6>\u001b[0m in \u001b[0;36mget_all_combs\u001b[0;34m(orig_list, binsizes, verbose)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# add to the top of stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchildren\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num of all possible combs: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-222-7eee86332bb6>\u001b[0m in \u001b[0;36mget_all_combs\u001b[0;34m(orig_list, binsizes, verbose)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# add to the top of stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchildren\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num of all possible combs: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai-cpu/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai-cpu/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_get_all_combs_2():\n",
    "    orig_list = np.array(range(7))\n",
    "    binsizes = [1,1,5]\n",
    "    result1 = get_all_combs(orig_list, binsizes, True)\n",
    "    \n",
    "test_get_all_combs_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_list:  [0 1 2 3 4]\n",
      "binsizes:  [2, 2]\n",
      "================================================================================\n",
      "Initial Queue of nodes [10]: \n",
      "\n",
      "CombNode(frozenset({0, 1}), p=None, level=1), Remaining: [2 3 4]\n",
      "CombNode(frozenset({0, 2}), p=None, level=1), Remaining: [1 3 4]\n",
      "CombNode(frozenset({0, 3}), p=None, level=1), Remaining: [1 2 4]\n",
      "CombNode(frozenset({0, 4}), p=None, level=1), Remaining: [1 2 3]\n",
      "CombNode(frozenset({1, 2}), p=None, level=1), Remaining: [0 3 4]\n",
      "CombNode(frozenset({1, 3}), p=None, level=1), Remaining: [0 2 4]\n",
      "CombNode(frozenset({1, 4}), p=None, level=1), Remaining: [0 2 3]\n",
      "CombNode(frozenset({2, 3}), p=None, level=1), Remaining: [0 1 4]\n",
      "CombNode(frozenset({2, 4}), p=None, level=1), Remaining: [0 1 3]\n",
      "CombNode(frozenset({3, 4}), p=None, level=1), Remaining: [0 1 2]\n",
      "================================================================================\n",
      "Num of all possible combs:  15\n",
      "\n",
      "Collection: \n",
      "frozenset({frozenset({3, 4}), frozenset({0, 2})})\n",
      "frozenset({frozenset({2, 4}), frozenset({0, 3})})\n",
      "frozenset({frozenset({1, 4}), frozenset({0, 3})})\n",
      "frozenset({frozenset({0, 1}), frozenset({2, 3})})\n",
      "frozenset({frozenset({0, 4}), frozenset({1, 2})})\n",
      "frozenset({frozenset({1, 3}), frozenset({0, 4})})\n",
      "frozenset({frozenset({0, 2}), frozenset({1, 3})})\n",
      "frozenset({frozenset({1, 2}), frozenset({0, 3})})\n",
      "frozenset({frozenset({3, 4}), frozenset({0, 1})})\n",
      "frozenset({frozenset({2, 3}), frozenset({0, 4})})\n",
      "frozenset({frozenset({1, 4}), frozenset({2, 3})})\n",
      "frozenset({frozenset({1, 4}), frozenset({0, 2})})\n",
      "frozenset({frozenset({3, 4}), frozenset({1, 2})})\n",
      "frozenset({frozenset({2, 4}), frozenset({1, 3})})\n",
      "frozenset({frozenset({0, 1}), frozenset({2, 4})})\n"
     ]
    }
   ],
   "source": [
    "def test_get_all_combs_3():\n",
    "    orig_list = np.array(range(5))\n",
    "    binsizes = [2,2]\n",
    "    result1 = get_all_combs(orig_list, binsizes, True)\n",
    "\n",
    "def test_get_all_combs_4():\n",
    "    \"\"\"\n",
    "    Testcase:  binsizes does not sum up to len(orig_list)\n",
    "    \"\"\"\n",
    "    orig_list = np.array(range(5))\n",
    "    binsizes = [1,2]\n",
    "    result1 = get_all_combs(orig_list, binsizes, True)\n",
    "    \n",
    "def test_get_all_combs_5():\n",
    "    \"\"\"\n",
    "    Testcase:  binsizes does not sum up to len(orig_list)\n",
    "    \"\"\"\n",
    "    orig_list = np.array(range(5))\n",
    "    binsizes = [2,2]\n",
    "    result1 = get_all_combs(orig_list, binsizes, True)\n",
    "\n",
    "test_get_all_combs_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUCCESS!! >.<!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_all_combs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0420e318a53b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_combs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_combs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msolve_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-0420e318a53b>\u001b[0m in \u001b[0;36msolve_problem\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_combs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbinsizes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbinsizes_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcombs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_combs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinsizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mall_combs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_all_combs' is not defined"
     ]
    }
   ],
   "source": [
    "def solve_problem():\n",
    "    orig_list = np.array(range(7))\n",
    "#     orig_list = np.array( [ 'a','b','c','d', 'e','f','g'] )\n",
    "    binsizes_list = [ [1,1,5], [1,2,4], [1,3,3], [2,2,3] ]\n",
    "    all_combs = []\n",
    "    for binsizes in binsizes_list:\n",
    "        combs = get_all_combs(orig_list, binsizes)\n",
    "        \n",
    "        all_combs.extend(combs)\n",
    "        nprint(f\"binsizes: {binsizes}\", len(combs))\n",
    "    print(\"Total: \", len(all_combs))\n",
    "    return all_combs\n",
    "solve_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESUME FROM HERE!\n",
    "todo:\n",
    "Left at 1pm \n",
    "- [ ] debug the first two cases and check all the others are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "---\n",
    "## TODO\n",
    "\n",
    "Timelog  \n",
    "Left 3/24/2019 (Mon)  7:30pm    \n",
    "Resumed 3/25/2019 (Tue) 10am  \n",
    "Resumed on 3/26/2019 (W) 10am\n",
    "Left 3/26/2019 (W) 1pm \n",
    "\n",
    "---\n",
    "- [ ] debug the first two cases and check all the others are correct\n",
    "---\n",
    "- [ ] Turn this notebook into a blog post  (2 pomos)\n",
    "---\n",
    "- [x] actually nCk needs to run this for each vertex as the starting vid\n",
    "- [x] This computation is needed at each horizontal level in the binning\n",
    "---\n",
    "- [ ] Incorporate this to the original binning problem (2 pomos)\n",
    "    - [x] Define a new subclass of Node which keeps a set of integers as its vid\n",
    "    - [ ] Find all possible groupsizes of size k:  \n",
    "    For example, if I have a list of length 7, I need to know all possible ways to divide 7     into a list of k positive integers that sum up to 7: (1,1,5), (1,2,4), (1,3,3), (2,2,3)\n",
    "    \n",
    "---\n",
    "Starting from 10pm?\n",
    "- [x] Strang Linear Algebra\n",
    "- [ ] Andrew Ng\n",
    "- [ ] MM\n",
    "- [ ] Murphy ch2,3\n",
    "- [ ] Reinforcement Learning\n",
    "- [ ] FastAI: UNet training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
